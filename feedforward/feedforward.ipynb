{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "PLOTTING_SUPPORT = True\n",
    "RUN_AS_PY_SCRIPT = False\n",
    "SET_EULER_PARAMS = False\n",
    "SET_MARMOT_PARAMS = False\n",
    "\n",
    "# Handle arguments (When executed as .py script)\n",
    "import sys\n",
    "argv = sys.argv[:]\n",
    "if len(argv) > 1:\n",
    "  script_path = argv.pop(0)\n",
    "  if \"--euler\" in argv:\n",
    "    import sys\n",
    "    sys.stdout = open('stdout.txt', 'w')\n",
    "    RUN_AS_PY_SCRIPT = True\n",
    "    PLOTTING_SUPPORT = False\n",
    "    SET_EULER_PARAMS = True\n",
    "    print(\"Parameters set for execution on euler cluster\")\n",
    "    argv.remove(\"--euler\")\n",
    "  if \"--marmot\" in argv:\n",
    "    RUN_AS_PY_SCRIPT = True\n",
    "    PLOTTING_SUPPORT = False\n",
    "    SET_MARMOT_PARAMS = True\n",
    "    print(\"Parameters set for execution on marmot cluster\")\n",
    "    argv.remove(\"--marmot\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not RUN_AS_PY_SCRIPT:\n",
    "  %load_ext autoreload\n",
    "  %autoreload 2\n",
    "  from IPython.display import clear_output\n",
    "  if PLOTTING_SUPPORT:\n",
    "    %matplotlib notebook\n",
    "    from matplotlib import pyplot as plt\n",
    "    plotting_function = plt.step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "MAX_STEPS = 10000\n",
    "VAL_EVERY_N_STEPS = 1\n",
    "VAL_STEP_TOLERANCE = 3\n",
    "\n",
    "MODEL = 'feedforward'\n",
    "if \"--lstm\" in argv:\n",
    "  MODEL = 'lstm'\n",
    "  print(\"LSTM Model Selected\")\n",
    "  argv.remove(\"--lstm\")\n",
    "if \"--feedforward\" in argv:\n",
    "  MODEL = 'feedforward'\n",
    "  print(\"Feedforward Model Selected\")\n",
    "  argv.remove(\"--feedforward\")   \n",
    "if MODEL == 'lstm':\n",
    "  from lstm import model\n",
    "  from lstm.quantize import *\n",
    "  from lstm.batchmaker import *\n",
    "elif MODEL == 'feedforward':\n",
    "  from ann import model\n",
    "  from ann.quantize import *\n",
    "  from ann.batchmaker import *\n",
    "\n",
    "MP = model.ModelParams()\n",
    "\n",
    "DATA_DIR = \"/home/daniel/Downloads/Raw-Waves/\"\n",
    "DATA_FILENAME=\"001_Session1_FilterTrigCh_RawCh.mat\"\n",
    "DATA2_FILENAME=\"001_Session2_FilterTrigCh_RawCh.mat\"\n",
    "DATA3_FILENAME=\"034_Session1_FilterTrigCh_RawCh.mat\"\n",
    "SAMPLING = 1\n",
    "MAX_VAL_DATA_LENGTH = 100000000\n",
    "MAX_TRAIN_DATA_LENGTH = 400000000\n",
    "TINY_DATASET = False\n",
    "FILTER_IN_SLEEP_WAVES = True\n",
    "\n",
    "RESTORE_MODEL = True\n",
    "SAVE_DIR = \"/home/daniel/Desktop/\"+MODEL+\"/\"\n",
    "SAVE_FILE = \"model.checkpoint\"\n",
    "MP_FILENAME = \"model_params.pckl\"\n",
    "TENSORBOARD_DIR = \"/home/daniel/tensorboard\"\n",
    "SAVE_UNVALIDATED = False\n",
    "DETAILED_STEP_TIMES = True\n",
    "PROGRESS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if SET_EULER_PARAMS:\n",
    "    DATA_DIR = \"/cluster/home/dugasd/Raw-Waves/\"\n",
    "    SAVE_DIR = \"/cluster/home/dugasd/\"+MODEL+\"-euler/\"\n",
    "    TENSORBOARD_DIR = None\n",
    "    \n",
    "    MAX_STEPS = 1000000\n",
    "    VAL_STEP_TOLERANCE = 5\n",
    "\n",
    "if SET_MARMOT_PARAMS:\n",
    "    DATA_DIR = \"/home/daniel/Raw-Waves/\"\n",
    "    SAVE_DIR = \"/home/daniel/\"+MODEL+\"-marmot/\"\n",
    "    TENSORBOARD_DIR = None\n",
    "    \n",
    "    MAX_STEPS = 1000000\n",
    "    VAL_STEP_TOLERANCE = 10\n",
    "    \n",
    "if not RUN_AS_PY_SCRIPT:\n",
    "    TINY_DATASET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if RUN_AS_PY_SCRIPT:\n",
    "  while argv:\n",
    "      arg = argv.pop(0)\n",
    "      if arg == \"-VAL_STEP_TOLERANCE\":\n",
    "        VAL_STEP_TOLERANCE = int(argv.pop(0))\n",
    "        print(\"VAL_STEP_TOLERANCE set to \" + str(VAL_STEP_TOLERANCE))\n",
    "      elif arg == \"-SAVE_DIR\":\n",
    "        SAVE_DIR = argv.pop(0)\n",
    "        print(\"SAVE_DIR set to \" + SAVE_DIR)\n",
    "      elif arg == \"-CLIP_GRADIENTS\":\n",
    "        MP.CLIP_GRADIENTS = float(argv.pop(0))\n",
    "        print(\"CLIP_GRADIENTS set to \" + str(MP.CLIP_GRADIENTS))\n",
    "      elif arg == \"-LEARNING_RATE\":\n",
    "        MP.LEARNING_RATE = float(argv.pop(0))\n",
    "        print(\"LEARNING_RATE set to \" + str(MP.LEARNING_RATE))\n",
    "      elif arg == \"--float64\":\n",
    "        MP.FLOAT_TYPE = tf.float64\n",
    "        print(\"MP.FLOAT_TYPE set to \" + str(MP.FLOAT_TYPE))\n",
    "      else:\n",
    "        print(\"Unknown argument: \" + arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = SAVE_DIR+SAVE_FILE\n",
    "if SAVE_UNVALIDATED:\n",
    "  SAVE_DIR_NOVAL = SAVE_DIR+\"unvalidated/\"\n",
    "  SAVE_PATH_NOVAL = SAVE_DIR_NOVAL+SAVE_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "  raw_wave = []\n",
    "\n",
    "  import scipy.io\n",
    "  mat = scipy.io.loadmat(DATA_DIR+DATA_FILENAME)\n",
    "  raw_wave = mat.get('data')[0]\n",
    "  raw_wave = raw_wave[::SAMPLING]\n",
    "  raw_wave = raw_wave/100 # volts -> microvolts\n",
    "  raw_wave[np.where(raw_wave>1)] = 1\n",
    "  raw_wave[np.where(raw_wave<-1)] = -1\n",
    "  wave_indices = mat.get('wave')[0].astype(int)\n",
    "    \n",
    "  # Save some memory\n",
    "  del mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_sleep_wave = np.zeros(raw_wave.shape)\n",
    "for i in range(wave_indices.shape[1]):\n",
    "  is_sleep_wave[wave_indices[0,i]:wave_indices[4,i]] = 1\n",
    "\n",
    "example_contains_sw = np.zeros(raw_wave.shape)\n",
    "for i in range(wave_indices.shape[1]):\n",
    "  example_contains_sw[wave_indices[0,i]-MP.WAVE_OUT_SHAPE[0]:wave_indices[4,i]+MP.WAVE_OUT_SHAPE[0]] = 1\n",
    "example_contains_sw = example_contains_sw[MP.WAVE_IN_SHAPE[0]:].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if TINY_DATASET:\n",
    "  HOW_TINY = 50000\n",
    "  raw_wave = raw_wave[np.where(example_contains_sw)[0][0]:][:HOW_TINY]\n",
    "  is_sleep_wave = is_sleep_wave[np.where(example_contains_sw)[0][0]:][:HOW_TINY]\n",
    "  example_contains_sw = example_contains_sw[np.where(example_contains_sw)[0][0]:][:HOW_TINY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not RUN_AS_PY_SCRIPT:\n",
    "  plt.figure(figsize=[100,8])\n",
    "  plotting_function(range(len(raw_wave)),raw_wave,label=\"raw_wave\")\n",
    "  plotting_function(range(len(is_sleep_wave)), is_sleep_wave, label=\"is_sleep_wave\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not RUN_AS_PY_SCRIPT:\n",
    "  try:\n",
    "    stored_MP = pickle.load(open(SAVE_DIR+MP_FILENAME, 'rb'))\n",
    "    MP = stored_MP\n",
    "    print(\"Set params for compatibility with stored model.\")\n",
    "  except FileNotFoundError:\n",
    "    print(\"No stored model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == 'lstm':\n",
    "  nn = model.LSTM(MP)\n",
    "elif MODEL == 'feedforward':\n",
    "  nn = model.Feedforward(MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False and TENSORBOARD_DIR != None:\n",
    "  summary_writer = tf.train.SummaryWriter(TENSORBOARD_DIR, nn.sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if RESTORE_MODEL:\n",
    "  try:\n",
    "    nn.saver.restore(nn.sess, SAVE_PATH)\n",
    "    print(\"Model restored.\")\n",
    "  except:\n",
    "    print(\"Could not load model: \", end=\"\")\n",
    "    try:\n",
    "      stored_MP = pickle.load(open(SAVE_DIR+MP_FILENAME, 'rb'))\n",
    "      print(\"mismatch between model params.\")\n",
    "      print(\"Stored model: \"); print(stored_MP); print(\"New model: \"); print(MP)\n",
    "    except:\n",
    "      print(\"no model folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split into training and val data\n",
    "split_at = min(MAX_VAL_DATA_LENGTH, int(0.2 * len(raw_wave)))\n",
    "val = raw_wave[:split_at]\n",
    "val_is_sleep = is_sleep_wave[:split_at]\n",
    "train = raw_wave[split_at:][:MAX_TRAIN_DATA_LENGTH]\n",
    "train_is_sleep = is_sleep_wave[split_at:][:MAX_TRAIN_DATA_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if FILTER_IN_SLEEP_WAVES:\n",
    "  val_contains_sw = example_contains_sw[:split_at]\n",
    "  train_contains_sw = example_contains_sw[split_at:][:MAX_TRAIN_DATA_LENGTH]\n",
    "else:\n",
    "  val_contains_sw = None\n",
    "  train_contains_sw = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model ( Computationally Intensive )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "progress_bar('reset')\n",
    "\n",
    "total_step_cost = None\n",
    "step_cost_log = []\n",
    "total_val_cost = 0\n",
    "val_steps_since_last_improvement = 0\n",
    "step_start = timer()\n",
    "\n",
    "try:\n",
    "    val_cost_log = list(np.loadtxt(SAVE_DIR+\"val_cost_log.txt\"))\n",
    "    print(\"Previous cost log found.\")\n",
    "except:\n",
    "    val_cost_log = []\n",
    "    \n",
    "print(\"Training started.\")\n",
    "for step in range(MAX_STEPS):\n",
    "  # Validation\n",
    "  val_batchmaker = Batchmaker(val, val_is_sleep, BATCH_SIZE, MP, example_filter=val_contains_sw)\n",
    "  if np.mod(step, VAL_EVERY_N_STEPS) == 0:\n",
    "    total_val_cost = 0\n",
    "    while True:\n",
    "      if val_batchmaker.is_depleted():\n",
    "        break\n",
    "      else:\n",
    "        batch_input_values, batch_target_values, batch_is_sleep_values = val_batchmaker.next_batch()\n",
    "        cost_value = nn.cost_on_single_batch(batch_input_values, batch_target_values, batch_is_sleep_values)\n",
    "        total_val_cost += cost_value\n",
    "        if PROGRESS:\n",
    "          progress_bar(val_batchmaker)\n",
    "    print(\"Validation cost: \"+str(total_val_cost)+\"  (Training cost: \"+str(total_step_cost)+\")\", end=\"\")\n",
    "    try:\n",
    "      print(\" Step Time: \" + str(step_end-step_start))\n",
    "      if DETAILED_STEP_TIMES:\n",
    "        print(step_times)\n",
    "    except: \n",
    "        print(\" \")\n",
    "    \n",
    "    val_cost_log.append(total_val_cost)\n",
    "    \n",
    "    # Training Monitor\n",
    "    if len(val_cost_log) > 1:\n",
    "        # Save cost log.\n",
    "        import os\n",
    "        if not os.path.exists(SAVE_DIR):\n",
    "            os.makedirs(SAVE_DIR)\n",
    "            if SAVE_UNVALIDATED: os.makedirs(SAVE_DIR_NOVAL)\n",
    "            print(\"Created directory: %s\" % SAVE_DIR)\n",
    "            with open(SAVE_DIR+MP_FILENAME, 'wb') as file:\n",
    "              pickle.dump(MP, file, protocol=2)\n",
    "        np.savetxt(SAVE_DIR+\"val_cost_log.txt\", val_cost_log)\n",
    "        # Save if cost has improved. Otherwise increment counter.\n",
    "        if val_cost_log[-1] <  min(val_cost_log[:-1]):\n",
    "            val_steps_since_last_improvement = 0\n",
    "            # save model to disk\n",
    "            print(\"Saving ... \", end='')\n",
    "            save_path = nn.saver.save(nn.sess, SAVE_PATH)\n",
    "            print(\"Model saved in file: %s\" % save_path)      \n",
    "        else:\n",
    "            val_steps_since_last_improvement += 1  \n",
    "    # Stop training if val_cost hasn't improved in VAL_STEP_TOLERANCE steps\n",
    "    if val_steps_since_last_improvement > VAL_STEP_TOLERANCE:\n",
    "        if SAVE_UNVALIDATED:\n",
    "            print(\"Saving ... \", end='')\n",
    "            save_path = nn.saver.save(nn.sess, SAVE_PATH_NOVAL)\n",
    "            print(\"Unvalidated model saved in file: %s\" % save_path)\n",
    "        print(\"Training stopped by validation monitor.\")\n",
    "        break\n",
    "            \n",
    "  # Train on batches\n",
    "  step_start = timer()\n",
    "  zero = timer() - timer()\n",
    "  step_times = {'batchmaking': zero, 'training': zero, 'plotting': zero}\n",
    "  total_step_cost = 0\n",
    "  training_batchmaker = Batchmaker(train, train_is_sleep, BATCH_SIZE, MP, example_filter=train_contains_sw)\n",
    "  while True:\n",
    "    if training_batchmaker.is_depleted():\n",
    "      break\n",
    "    else:\n",
    "      t_a = timer()  \n",
    "      batch_input_values, batch_target_values, batch_is_sleep_values = training_batchmaker.next_batch()\n",
    "      t_b = timer()\n",
    "      # Train over 1 batch.\n",
    "      cost_value = nn.train_on_single_batch(batch_input_values, batch_target_values, batch_is_sleep_values)\n",
    "      total_step_cost += cost_value\n",
    "      t_c = timer()\n",
    "      if PROGRESS:\n",
    "        progress_bar(training_batchmaker)\n",
    "      t_d = timer()\n",
    "      step_times['batchmaking'] += t_b - t_a\n",
    "      step_times['training']    += t_c - t_b\n",
    "      step_times['plotting']    += t_d - t_c\n",
    "  step_cost_log.append(total_step_cost)\n",
    "  step_end = timer()\n",
    "\n",
    "\n",
    "print(\"Training ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not RUN_AS_PY_SCRIPT:\n",
    "  TRAIN = False\n",
    "  advance_by = 10\n",
    "  dir_ = \"/tmp/brain_waves/\";\n",
    "  if not os.path.exists(dir_): os.makedirs(dir_)\n",
    "  plt.close('all')\n",
    "  import time\n",
    "  \n",
    "  total_step_cost = None\n",
    "  step_cost_log = []\n",
    "  test_batchmaker = Batchmaker(val, val_is_sleep, 1, MP, example_filter=None, shuffle_examples=False)\n",
    "  full_is_sleep = [];  full_is_sleep_pred = [];  full_ground_truth = [];  full_prediction = []; count = 0\n",
    "  # single step\n",
    "  while True:\n",
    "      # Validation\n",
    "      if test_batchmaker.is_depleted(): break\n",
    "      for i in range(advance_by):\n",
    "        if test_batchmaker.is_depleted(): break\n",
    "        X, Y, IS = test_batchmaker.next_batch()\n",
    "      Y_pred, IS_pred = nn.predict(X)\n",
    "      plt.figure('dynamic_predictions')\n",
    "      plt.clf()\n",
    "      plt.subplot(2,1,1)\n",
    "      plt.title('Wave Prediction')\n",
    "      plt.plot(range(len(X[0])), X[0])\n",
    "      plt.plot(range(len(X[0])), -X[0], alpha=0)\n",
    "      if MP.ESTIMATOR['type'] == 'quantized':\n",
    "        y = inverse_mu_law(unquantize(quantize(mu_law(Y[0]),MP.ESTIMATOR['bins'])))\n",
    "        plt.step(range(len(y)), y, label='ground truth')\n",
    "        y = inverse_mu_law(unquantize(pick_max(Y_pred[0])))\n",
    "      else:\n",
    "        y = Y_pred[0][:,:,0]\n",
    "      plt.step(range(len(X[0]),len(y)+len(X[0])), y, label='prediction')\n",
    "      plt.plot(range(len(X[0]),len(Y[0])+len(X[0])), Y[0])\n",
    "      plt.axvline(len(X[0]), color='k')\n",
    "      xlim = plt.xlim()\n",
    "      plt.subplot(2,1,2)\n",
    "      plt.title('Label Prediction')\n",
    "      padded_IS = np.zeros(MP.WAVE_IN_SHAPE[0]) * np.nan\n",
    "      latest_is = full_is_sleep[-MP.WAVE_IN_SHAPE[0]:]\n",
    "      padded_IS[-len(latest_is):] = latest_is if len(latest_is) != 0 else padded_IS\n",
    "      padded_pred = np.zeros(MP.WAVE_IN_SHAPE[0]) * np.nan\n",
    "      latest_pred = full_is_sleep_pred[-MP.WAVE_IN_SHAPE[0]:]\n",
    "      padded_pred[-len(latest_pred):] = latest_pred if len(latest_pred) != 0 else padded_pred\n",
    "      plt.step(range(len(padded_IS)), padded_IS, label='past ground truth')\n",
    "      plt.step(range(len(padded_IS),len(padded_IS)+len(IS[0])), IS[0], 'c', label='ground truth')\n",
    "      plt.plot(range(len(padded_pred)), padded_pred, 'r--', label='past prediction')\n",
    "      plt.plot(range(len(X[0]),len(IS_pred[0])+len(X[0])), IS_pred[0], 'r', label='prediction')\n",
    "      plt.ylim([-0.1, 1.1])\n",
    "      plt.xlim(xlim)\n",
    "      plt.axvline(len(X[0]), color='k')\n",
    "      plt.show()\n",
    "      plt.gcf().canvas.draw()\n",
    "      plt.savefig(dir_+\"frame\"+str(count).zfill(4)); count = count+1\n",
    "      time.sleep(0.001)\n",
    "      full_is_sleep = full_is_sleep + list(IS[0][:advance_by]);\n",
    "      full_is_sleep_pred = full_is_sleep_pred + list(IS_pred[0][:advance_by])\n",
    "      full_ground_truth = full_ground_truth + list(Y[0][:advance_by]);\n",
    "      full_prediction = full_prediction + list(Y_pred[0][:advance_by])\n",
    "    \n",
    "      total_step_cost = 0\n",
    "      if TRAIN:\n",
    "        training_batchmaker = Batchmaker(train, train_is_sleep, BATCH_SIZE, MP, example_filter=train_contains_sw)\n",
    "        while True:\n",
    "          if training_batchmaker.is_depleted():\n",
    "            break\n",
    "          else:\n",
    "            batch_input_values, batch_target_values, batch_is_sleep_values = training_batchmaker.next_batch()\n",
    "            # Train over 1 batch.\n",
    "            cost_value = nn.train_on_single_batch(batch_input_values, batch_target_values, batch_is_sleep_values)\n",
    "            total_step_cost += cost_value\n",
    "        step_cost_log.append(total_step_cost)\n",
    "        plt.figure('training_evolution')\n",
    "        plt.plot(step_cost_log)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not RUN_AS_PY_SCRIPT:\n",
    "  plt.figure(figsize=[100,10])\n",
    "  plt.subplot(2,1,1)\n",
    "  plt.plot(np.array(full_prediction)[:,:,0])\n",
    "  plt.plot(-np.array(full_ground_truth), alpha=0)\n",
    "  plt.plot(np.array(full_ground_truth))\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.plot(np.array(full_is_sleep), 'r')\n",
    "  plt.plot(np.array(full_is_sleep_pred))\n",
    "  plt.ylim([-0.1,1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ml3]",
   "language": "python",
   "name": "Python [ml3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
