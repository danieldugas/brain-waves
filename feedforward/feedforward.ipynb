{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from ann import model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "PLOTTING_SUPPORT = True\n",
    "RUN_AS_PY_SCRIPT = False\n",
    "SET_EULER_PARAMS = False\n",
    "SET_MARMOT_PARAMS = False\n",
    "\n",
    "# Handle arguments (When executed as .py script)\n",
    "import sys\n",
    "argv = sys.argv[:]\n",
    "if len(argv) > 1:\n",
    "  script_path = argv.pop(0)\n",
    "  if \"--euler\" in argv:\n",
    "    import sys\n",
    "    sys.stdout = open('stdout.txt', 'w')\n",
    "    RUN_AS_PY_SCRIPT = True\n",
    "    PLOTTING_SUPPORT = False\n",
    "    SET_EULER_PARAMS = True\n",
    "    print(\"Parameters set for execution on euler cluster\")\n",
    "    argv.remove(\"--euler\")\n",
    "  if \"--marmot\" in argv:\n",
    "    RUN_AS_PY_SCRIPT = True\n",
    "    PLOTTING_SUPPORT = False\n",
    "    SET_MARMOT_PARAMS = True\n",
    "    print(\"Parameters set for execution on marmot cluster\")\n",
    "    argv.remove(\"--marmot\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not RUN_AS_PY_SCRIPT:\n",
    "  %load_ext autoreload\n",
    "  %autoreload 2\n",
    "  from IPython.display import clear_output\n",
    "  if PLOTTING_SUPPORT:\n",
    "    %matplotlib notebook\n",
    "    from matplotlib import pyplot as plt\n",
    "    plotting_function = plt.step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "MAX_STEPS = 10000\n",
    "VAL_EVERY_N_STEPS = 1\n",
    "VAL_STEP_TOLERANCE = 3\n",
    "\n",
    "MP = model.ModelParams()\n",
    "MP.WAVE_IN_SHAPE = [1000]\n",
    "MP.WAVE_OUT_SHAPE = [100]\n",
    "MP.HIDDEN_LAYERS = [{'shape': [400]}, {'shape': [400]}]\n",
    "MP.QUANTIZATION = 10\n",
    "MP.DROPOUT = 0.8\n",
    "MP.LEARNING_RATE = 0.00001\n",
    "\n",
    "DATA_DIR = \"/home/daniel/Downloads/Raw-Waves/\"\n",
    "DATA_FILENAME=\"001_Session1_FilterTrigCh_RawCh.mat\"\n",
    "DATA2_FILENAME=\"001_Session2_FilterTrigCh_RawCh.mat\"\n",
    "DATA3_FILENAME=\"034_Session1_FilterTrigCh_RawCh.mat\"\n",
    "SAMPLING = 1\n",
    "MAX_VAL_DATA_LENGTH = 100000000\n",
    "MAX_TRAIN_DATA_LENGTH = 400000000\n",
    "TINY_DATASET = False\n",
    "FILTER_IN_SLEEP_WAVES = True\n",
    "\n",
    "RESTORE_MODEL = True\n",
    "SAVE_DIR = \"/home/daniel/Desktop/feedforward/\"\n",
    "SAVE_FILE = \"model.checkpoint\"\n",
    "MP_FILENAME = \"model_params.pckl\"\n",
    "TENSORBOARD_DIR = \"/home/daniel/tensorboard\"\n",
    "SAVE_UNVALIDATED = False\n",
    "DETAILED_STEP_TIMES = True\n",
    "PROGRESS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if SET_EULER_PARAMS:\n",
    "    DATA_DIR = \"/cluster/home/dugasd/Raw-Waves/\"\n",
    "    SAVE_DIR = \"/cluster/home/dugasd/feedforward-euler/\"\n",
    "    TENSORBOARD_DIR = None\n",
    "    \n",
    "    MAX_STEPS = 1000000\n",
    "    VAL_STEP_TOLERANCE = 5\n",
    "\n",
    "if SET_MARMOT_PARAMS:\n",
    "    DATA_DIR = \"/home/daniel/Raw-Waves/\"\n",
    "    SAVE_DIR = \"/home/daniel/feedforward-marmot/\"\n",
    "    TENSORBOARD_DIR = None\n",
    "    \n",
    "    MAX_STEPS = 1000000\n",
    "    VAL_STEP_TOLERANCE = 10\n",
    "    \n",
    "if not RUN_AS_PY_SCRIPT:\n",
    "    #MAX_STEPS = 0\n",
    "    VAL_STEP_TOLERANCE = 10\n",
    "    MP.QUANTIZATION = 10\n",
    "    MP.HIDDEN_LAYERS = [{'shape': [100]}, {'shape': [20]}]\n",
    "    TINY_DATASET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if RUN_AS_PY_SCRIPT:\n",
    "  while argv:\n",
    "      arg = argv.pop(0)\n",
    "      if arg == \"-VAL_STEP_TOLERANCE\":\n",
    "        VAL_STEP_TOLERANCE = int(argv.pop(0))\n",
    "        print(\"VAL_STEP_TOLERANCE set to \" + str(VAL_STEP_TOLERANCE))\n",
    "      elif arg == \"-SAVE_DIR\":\n",
    "        SAVE_DIR = argv.pop(0)\n",
    "        print(\"SAVE_DIR set to \" + SAVE_DIR)\n",
    "      elif arg == \"-CLIP_GRADIENTS\":\n",
    "        MP.CLIP_GRADIENTS = float(argv.pop(0))\n",
    "        print(\"CLIP_GRADIENTS set to \" + str(MP.CLIP_GRADIENTS))\n",
    "      elif arg == \"--float64\":\n",
    "        MP.FLOAT_TYPE = tf.float64\n",
    "        print(\"MP.FLOAT_TYPE set to \" + str(MP.FLOAT_TYPE))\n",
    "      else:\n",
    "        print(\"Unknown argument: \" + arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = SAVE_DIR+SAVE_FILE\n",
    "if SAVE_UNVALIDATED:\n",
    "  SAVE_DIR_NOVAL = SAVE_DIR+\"unvalidated/\"\n",
    "  SAVE_PATH_NOVAL = SAVE_DIR_NOVAL+SAVE_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "  raw_wave = []\n",
    "\n",
    "  import scipy.io\n",
    "  mat = scipy.io.loadmat(DATA_DIR+DATA_FILENAME)\n",
    "  raw_wave = mat.get('data')[0]\n",
    "  raw_wave = raw_wave[::SAMPLING]\n",
    "  raw_wave = raw_wave/100 # volts -> microvolts\n",
    "  raw_wave[np.where(raw_wave>1)] = 1\n",
    "  raw_wave[np.where(raw_wave<-1)] = -1\n",
    "  wave_indices = mat.get('wave')[0].astype(int)\n",
    "    \n",
    "  # Save some memory\n",
    "  del mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_sleep_wave = np.zeros(raw_wave.shape)\n",
    "for i in range(wave_indices.shape[1]):\n",
    "  is_sleep_wave[wave_indices[0,i]:wave_indices[4,i]] = 1\n",
    "\n",
    "example_contains_sw = np.zeros(raw_wave.shape)\n",
    "for i in range(wave_indices.shape[1]):\n",
    "  example_contains_sw[wave_indices[0,i]-MP.WAVE_OUT_SHAPE[0]:wave_indices[4,i]+MP.WAVE_OUT_SHAPE[0]] = 1\n",
    "example_contains_sw = example_contains_sw[MP.WAVE_IN_SHAPE[0]:].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if TINY_DATASET:\n",
    "  raw_wave = raw_wave[np.where(example_contains_sw)[0][0]:][:10000]\n",
    "  is_sleep_wave = is_sleep_wave[np.where(example_contains_sw)[0][0]:][:10000]\n",
    "  example_contains_sw = example_contains_sw[np.where(example_contains_sw)[0][0]:][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not RUN_AS_PY_SCRIPT:\n",
    "  plt.figure()\n",
    "  plotting_function(range(len(raw_wave)),raw_wave,label=\"raw_wave\")\n",
    "  plotting_function(range(len(is_sleep_wave)), is_sleep_wave, label=\"is_sleep_wave\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not RUN_AS_PY_SCRIPT:\n",
    "  try:\n",
    "    stored_MP = pickle.load(open(SAVE_DIR+MP_FILENAME, 'rb'))\n",
    "    MP = stored_MP\n",
    "    print(\"Set params for compatibility with stored model.\")\n",
    "  except FileNotFoundError:\n",
    "    print(\"No stored model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ff = model.Feedforward(MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if TENSORBOARD_DIR != None:\n",
    "  summary_writer = tf.train.SummaryWriter(TENSORBOARD_DIR, ff.sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if RESTORE_MODEL:\n",
    "  try:\n",
    "    ff.saver.restore(ff.sess, SAVE_PATH)\n",
    "    print(\"Model restored.\")\n",
    "  except:\n",
    "    print(\"Could not load model: \", end=\"\")\n",
    "    try:\n",
    "      stored_MP = pickle.load(open(SAVE_DIR+MP_FILENAME, 'rb'))\n",
    "      print(\"mismatch between model params.\")\n",
    "      print(\"Stored model: \"); print(stored_MP); print(\"New model: \"); print(MP)\n",
    "    except:\n",
    "      print(\"no model folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split into training and val data\n",
    "split_at = min(MAX_VAL_DATA_LENGTH, int(0.2 * len(raw_wave)))\n",
    "val = raw_wave[:split_at]\n",
    "val_is_sleep = is_sleep_wave[:split_at]\n",
    "train = raw_wave[split_at:][:MAX_TRAIN_DATA_LENGTH]\n",
    "train_is_sleep = is_sleep_wave[split_at:][:MAX_TRAIN_DATA_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if FILTER_IN_SLEEP_WAVES:\n",
    "  val_contains_sw = example_contains_sw[:split_at]\n",
    "  train_contains_sw = example_contains_sw[split_at:][:MAX_TRAIN_DATA_LENGTH]\n",
    "else:\n",
    "  val_contains_sw = None\n",
    "  train_contains_sw = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model ( Computationally Intensive )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from ann.batchmaker import Batchmaker, progress_bar\n",
    "progress_bar('reset')\n",
    "\n",
    "total_step_cost = None\n",
    "step_cost_log = []\n",
    "total_val_cost = 0\n",
    "val_steps_since_last_improvement = 0\n",
    "step_start = timer()\n",
    "\n",
    "try:\n",
    "    val_cost_log = list(np.loadtxt(SAVE_DIR+\"val_cost_log.txt\"))\n",
    "    print(\"Previous cost log found.\")\n",
    "except:\n",
    "    val_cost_log = []\n",
    "    \n",
    "print(\"Training started.\")\n",
    "for step in range(MAX_STEPS):\n",
    "  # Validation\n",
    "  val_batchmaker = Batchmaker(val, val_is_sleep, BATCH_SIZE, MP, example_filter=val_contains_sw)\n",
    "  if np.mod(step, VAL_EVERY_N_STEPS) == 0:\n",
    "    total_val_cost = 0\n",
    "    while True:\n",
    "      if val_batchmaker.is_depleted():\n",
    "        break\n",
    "      else:\n",
    "        batch_input_values, batch_target_values, batch_is_sleep_values = val_batchmaker.next_batch()\n",
    "        cost_value = ff.cost_on_single_batch(batch_input_values, batch_target_values, batch_is_sleep_values)\n",
    "        total_val_cost += cost_value\n",
    "        if PROGRESS:\n",
    "          progress_bar(val_batchmaker)\n",
    "    print(\"Validation cost: \"+str(total_val_cost)+\"  (Training cost: \"+str(total_step_cost)+\")\", end=\"\")\n",
    "    try:\n",
    "      print(\" Step Time: \" + str(step_end-step_start))\n",
    "      if DETAILED_STEP_TIMES:\n",
    "        print(step_times)\n",
    "    except: \n",
    "        print(\" \")\n",
    "    \n",
    "    val_cost_log.append(total_val_cost)\n",
    "    \n",
    "    # Training Monitor\n",
    "    if len(val_cost_log) > 1:\n",
    "        # Save cost log.\n",
    "        import os\n",
    "        if not os.path.exists(SAVE_DIR):\n",
    "            os.makedirs(SAVE_DIR)\n",
    "            if SAVE_UNVALIDATED: os.makedirs(SAVE_DIR_NOVAL)\n",
    "            print(\"Created directory: %s\" % SAVE_DIR)\n",
    "            with open(SAVE_DIR+MP_FILENAME, 'wb') as file:\n",
    "              pickle.dump(MP, file, protocol=2)\n",
    "        np.savetxt(SAVE_DIR+\"val_cost_log.txt\", val_cost_log)\n",
    "        # Save if cost has improved. Otherwise increment counter.\n",
    "        if val_cost_log[-1] <  min(val_cost_log[:-1]):\n",
    "            val_steps_since_last_improvement = 0\n",
    "            # save model to disk\n",
    "            print(\"Saving ... \", end='')\n",
    "            save_path = ff.saver.save(ff.sess, SAVE_PATH)\n",
    "            print(\"Model saved in file: %s\" % save_path)      \n",
    "        else:\n",
    "            val_steps_since_last_improvement += 1  \n",
    "    # Stop training if val_cost hasn't improved in VAL_STEP_TOLERANCE steps\n",
    "    if val_steps_since_last_improvement > VAL_STEP_TOLERANCE:\n",
    "        if SAVE_UNVALIDATED:\n",
    "            print(\"Saving ... \", end='')\n",
    "            save_path = ff.saver.save(ff.sess, SAVE_PATH_NOVAL)\n",
    "            print(\"Unvalidated model saved in file: %s\" % save_path)\n",
    "        print(\"Training stopped by validation monitor.\")\n",
    "        break\n",
    "            \n",
    "  # Train on batches\n",
    "  step_start = timer()\n",
    "  zero = timer() - timer()\n",
    "  step_times = {'batchmaking': zero, 'training': zero, 'plotting': zero}\n",
    "  total_step_cost = 0\n",
    "  training_batchmaker = Batchmaker(train, train_is_sleep, BATCH_SIZE, MP, example_filter=train_contains_sw)\n",
    "  while True:\n",
    "    if training_batchmaker.is_depleted():\n",
    "      break\n",
    "    else:\n",
    "      t_a = timer()  \n",
    "      batch_input_values, batch_target_values, batch_is_sleep_values = training_batchmaker.next_batch()\n",
    "      t_b = timer()\n",
    "      # Train over 1 batch.\n",
    "      cost_value = ff.train_on_single_batch(batch_input_values, batch_target_values, batch_is_sleep_values)\n",
    "      total_step_cost += cost_value\n",
    "      t_c = timer()\n",
    "      if PROGRESS:\n",
    "        progress_bar(training_batchmaker)\n",
    "      t_d = timer()\n",
    "      step_times['batchmaking'] += t_b - t_a\n",
    "      step_times['training']    += t_c - t_b\n",
    "      step_times['plotting']    += t_d - t_c\n",
    "  step_cost_log.append(total_step_cost)\n",
    "  step_end = timer()\n",
    "\n",
    "\n",
    "print(\"Training ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not RUN_AS_PY_SCRIPT:\n",
    "  plt.close('all')\n",
    "  import time\n",
    "  from ann.batchmaker import Batchmaker\n",
    "  \n",
    "  total_step_cost = None\n",
    "  step_cost_log = []\n",
    "\n",
    "  # single step\n",
    "  while True:\n",
    "      # Validation\n",
    "      test_batchmaker = Batchmaker(val, val_is_sleep, 1, MP, example_filter=val_contains_sw, shuffle_examples=True)\n",
    "      X, Y, IS = test_batchmaker.next_batch()\n",
    "      Y_pred, IS_pred = ff.predict(X)\n",
    "      from ann.quantize import *\n",
    "      plt.clf()\n",
    "      plt.figure('training_evo')\n",
    "      plt.subplot(2,2,1)\n",
    "      plt.plot(X[0])\n",
    "      plt.subplot(2,2,2)\n",
    "      y = inverse_mu_law(unquantize(quantize(mu_law(Y[0]),MP.QUANTIZATION)))\n",
    "      plt.step(range(len(y)), y, label='ground truth')\n",
    "      y = inverse_mu_law(unquantize(pick_max(Y_pred[0])))\n",
    "      plt.step(range(len(y)), y, label='prediction')\n",
    "      plt.plot(Y[0])\n",
    "      plt.subplot(2,2,4)\n",
    "      plt.step(range(len(IS[0])), IS[0], label='ground truth')\n",
    "      plt.step(range(len(IS_pred[0])), IS_pred[0], label='prediction')\n",
    "      plt.ylim([-0.1, 1.1])\n",
    "      plt.subplot(2,2,3)\n",
    "      plt.plot(step_cost_log)\n",
    "      plt.show()\n",
    "      plt.gcf().canvas.draw()\n",
    "      time.sleep(0.1)\n",
    "    \n",
    "      # Train on batches\n",
    "      total_step_cost = 0\n",
    "      training_batchmaker = Batchmaker(train, train_is_sleep, BATCH_SIZE, MP, example_filter=train_contains_sw)\n",
    "      while True:\n",
    "        if training_batchmaker.is_depleted():\n",
    "          break\n",
    "        else:\n",
    "          batch_input_values, batch_target_values, batch_is_sleep_values = training_batchmaker.next_batch()\n",
    "          # Train over 1 batch.\n",
    "          cost_value = ff.train_on_single_batch(batch_input_values, batch_target_values, batch_is_sleep_values)\n",
    "          total_step_cost += cost_value\n",
    "      step_cost_log.append(total_step_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ml3]",
   "language": "python",
   "name": "Python [ml3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
