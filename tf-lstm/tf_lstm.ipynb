{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PLOTTING_SUPPORT = True\n",
    "SET_EULER_PARAMETERS = False\n",
    "\n",
    "# Handle arguments (When executed as .py script)\n",
    "import sys\n",
    "argv = sys.argv[:]\n",
    "if len(argv) > 1:\n",
    "  script_path = argv.pop(0)\n",
    "  if \"--euler\" in argv:\n",
    "    SET_EULER_PARAMETERS = True\n",
    "    PLOTTING_SUPPORT = False\n",
    "    print(\"Parameters set for execution on euler cluster\")\n",
    "    argv.remove(\"--euler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"/home/daniel/Downloads/Data_200Hz/\"\n",
    "DATA_FILENAME=\"077_COSession1.set\"\n",
    "DATA2_FILENAME=\"077_COSession2.set\"\n",
    "ELECTRODES_OF_INTEREST = ['E36','E22','E9','E33','E24','E11','E124','E122','E45','E104',\n",
    "                          'E108','E58','E52','E62','E92','E96','E70','E83','E75']\n",
    "BATCH_SIZE = 20\n",
    "BATCH_LIMIT_PER_STEP = 10\n",
    "TRAINING_DATA_LENGTH = \"max\"\n",
    "VAL_DATA_LENGTH = 1200000\n",
    "TEST_DATA_LENGTH = 2000\n",
    "SAMPLING = 1\n",
    "\n",
    "MAX_STEPS = 1000\n",
    "\n",
    "VAL_EVERY_N_STEPS = 1\n",
    "VAL_STEP_TOLERANCE = 100\n",
    "\n",
    "class ModelParams:\n",
    "  def __init__(self):\n",
    "    self.BPTT_LENGTH = 100\n",
    "    self.OUTSET_CUTOFF = 50\n",
    "    self.NUM_UNITS = 512\n",
    "    self.N_LAYERS = 3\n",
    "    self.INPUT_SIZE = 19\n",
    "    self.OUTPUT_SIZE = 19\n",
    "    self.LEARNING_RATE = 0.001\n",
    "    self.CLIP_GRADIENTS = 1.0\n",
    "    self.SCALE_OUTPUT = 100.0\n",
    "    self.DROPOUT = 1.0\n",
    "  def __str__(self):\n",
    "    return str(self.__dict__)\n",
    "  def __eq__(self, other): \n",
    "    return self.__dict__ == other.__dict__\n",
    "  def __ne__(self, other):\n",
    "    return not self.__eq__(other)\n",
    "MP = ModelParams()\n",
    "\n",
    "SAVE_DIR = \"/home/daniel/Desktop/tf-lstm-model/\"\n",
    "SAVE_FILE = \"model.ckpt\"\n",
    "TENSORBOARD_DIR = \"/home/daniel/tensorboard\"\n",
    "#DATA_FOLDER = \"/home/daniel/Downloads/Raw-Waves/\"\n",
    "#DATA_FILENAME=\"001_Session1_FilterTrigCh_RawCh.mat\"\n",
    "#DATA2_FILENAME=\"001_Session2_FilterTrigCh_RawCh.mat\"\n",
    "#DATA3_FILENAME=\"034_Session1_FilterTrigCh_RawCh.mat\"\n",
    "\n",
    "assert MP.INPUT_SIZE == len(ELECTRODES_OF_INTEREST)\n",
    "assert MP.INPUT_SIZE == MP.OUTPUT_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if SET_EULER_PARAMETERS:\n",
    "    DATA_FOLDER = \"/cluster/home/dugasd/Data_200Hz/\"\n",
    "    SAVE_DIR = \"/cluster/home/dugasd/tf-lstm-model/\"\n",
    "    TENSORBOARD_DIR = None\n",
    "    \n",
    "    BATCH_SIZE = 20\n",
    "    BATCH_LIMIT_PER_STEP = 10000\n",
    "    MAX_STEPS = 1000000\n",
    "    VAL_STEP_TOLERANCE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if PLOTTING_SUPPORT:\n",
    "  import matplotlib.pyplot as plt\n",
    "  %matplotlib inline\n",
    "  from cycler import cycler\n",
    "  if SAMPLING > 0:\n",
    "      plotting_function = plt.step\n",
    "  else:\n",
    "      plotting_function = plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = SAVE_DIR+SAVE_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  raw_wave = []\n",
    "  raw_wave2 = []\n",
    "  raw_wave3 = []\n",
    "\n",
    "  import scipy.io\n",
    "  mat = scipy.io.loadmat(DATA_FOLDER+DATA_FILENAME)\n",
    "  raw_wave = mat.get('data')[0]\n",
    "  raw_wave = raw_wave[::SAMPLING]\n",
    "  raw_wave = raw_wave[0:]\n",
    "\n",
    "  if DATA2_FILENAME is not None:\n",
    "      mat = scipy.io.loadmat(DATA_FOLDER+DATA2_FILENAME)\n",
    "      raw_wave2 = mat.get('data')[0]\n",
    "      raw_wave2 = raw_wave2[::SAMPLING]\n",
    "      raw_wave2 = raw_wave2[0:]\n",
    "  if DATA3_FILENAME is not None:\n",
    "      mat = scipy.io.loadmat(DATA_FOLDER+DATA3_FILENAME)\n",
    "      raw_wave3 = mat.get('data')[0]\n",
    "      raw_wave3 = raw_wave3[::SAMPLING]\n",
    "      raw_wave3 = raw_wave3[0:]\n",
    "    \n",
    "  # Save some memory\n",
    "  del mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  raw_wave = []\n",
    "  raw_wave2 = []\n",
    "  raw_wave3 = []\n",
    " \n",
    "  import mne\n",
    "  raw_eeglab = mne.io.read_raw_eeglab(DATA_FOLDER+DATA_FILENAME)\n",
    "  electrode_names = raw_eeglab.ch_names\n",
    "  EOI_indices = [electrode_names.index(name) for name in ELECTRODES_OF_INTEREST]\n",
    "  raw_wave = np.array([raw_eeglab[e_index][0][0] for e_index in EOI_indices])\n",
    "  raw_wave = list(raw_wave.T)\n",
    "  raw_wave = raw_wave[::SAMPLING]*1000000\n",
    "\n",
    "  raw_eeglab = mne.io.read_raw_eeglab(DATA_FOLDER+DATA2_FILENAME)\n",
    "  electrode_names = raw_eeglab.ch_names\n",
    "  EOI_indices = [electrode_names.index(name) for name in ELECTRODES_OF_INTEREST]\n",
    "  raw_wave2 = np.array([raw_eeglab[e_index][0][0] for e_index in EOI_indices])\n",
    "  raw_wave2 = list(raw_wave2.T)\n",
    "  raw_wave2 = raw_wave2[::SAMPLING]*1000000\n",
    "\n",
    "  del raw_eeglab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  ARTEFACTS_FILENAME = \"077_Session1_artefact.mat\"\n",
    "  import scipy.io\n",
    "  mat = scipy.io.loadmat(DATA_FOLDER+ARTEFACTS_FILENAME)\n",
    "  artefacts = mat.get('artndxn')\n",
    "  artefacts = np.sum(artefacts, axis=0)\n",
    "\n",
    "  ARTEFACTS2_FILENAME = \"077_Session2_artefact.mat\"\n",
    "  mat = scipy.io.loadmat(DATA_FOLDER+ARTEFACTS2_FILENAME)\n",
    "  artefacts2 = mat.get('artndxn')\n",
    "  artefacts2 = np.sum(artefacts2, axis=0)\n",
    "  # Save some memory\n",
    "  del mat\n",
    "\n",
    "  artefacts = np.pad(artefacts[:,None], ((0,0),(0,20*200)), 'edge').flatten()\n",
    "  print(raw_wave.shape)\n",
    "  print(artefacts.shape)\n",
    "\n",
    "  artefacts2 = np.pad(artefacts2[:,None], ((0,0),(0,20*200)), 'edge').flatten()\n",
    "  print(raw_wave2.shape)\n",
    "  print(artefacts2.shape)\n",
    "\n",
    "  plt.figure(figsize=(100,10))\n",
    "  plotting_function(np.arange(len(artefacts)), artefacts)\n",
    "  plotting_function(range(len(raw_wave)), raw_wave[:,:3])\n",
    "  plt.ylim([-300,300])\n",
    "  plt.show()\n",
    "    \n",
    "  raw_wave = raw_wave[np.where(artefacts == artefacts.max())]\n",
    "  del artefacts\n",
    "  raw_wave2 = raw_wave2[np.where(artefacts2 == artefacts2.max())]\n",
    "  del artefacts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  np.save(DATA_FOLDER+\"raw_wave\", raw_wave)\n",
    "  np.save(DATA_FOLDER+\"raw_wave2\", raw_wave2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "  raw_wave  = np.load(DATA_FOLDER+\"raw_wave.npy\")\n",
    "  raw_wave2 = np.load(DATA_FOLDER+\"raw_wave2.npy\")\n",
    "  raw_wave  = raw_wave[::SAMPLING]\n",
    "  raw_wave2 = raw_wave2[::SAMPLING]\n",
    "  raw_wave3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if TRAINING_DATA_LENGTH == \"max\":\n",
    "    TRAINING_DATA_LENGTH = len(raw_wave)\n",
    "if VAL_DATA_LENGTH == \"max\":\n",
    "    assert len(raw_wave2) != 0\n",
    "    VAL_DATA_LENGTH = len(raw_wave2) - TEST_DATA_LENGTH\n",
    "assert TRAINING_DATA_LENGTH + VAL_DATA_LENGTH + TEST_DATA_LENGTH <= len(raw_wave) + len(raw_wave2) + len(raw_wave3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assign data to datasets.\n",
    "training_data = raw_wave[:TRAINING_DATA_LENGTH]\n",
    "if len(raw_wave2) is 0:\n",
    "  val_data = raw_wave[TRAINING_DATA_LENGTH:][:VAL_DATA_LENGTH]\n",
    "  test_data = raw_wave[TRAINING_DATA_LENGTH:][VAL_DATA_LENGTH:][:TEST_DATA_LENGTH]\n",
    "else:\n",
    "  val_data = raw_wave2[:VAL_DATA_LENGTH]\n",
    "  if len(raw_wave3) is 0:\n",
    "    test_data = raw_wave2[VAL_DATA_LENGTH:][:TEST_DATA_LENGTH]\n",
    "  else:\n",
    "    test_data = raw_wave3[:TEST_DATA_LENGTH]\n",
    "\n",
    "\n",
    "if PLOTTING_SUPPORT:\n",
    "  plt.figure(figsize=(500,10))\n",
    "  plotting_function(range(TRAINING_DATA_LENGTH),training_data[:,0],label=\"training\")\n",
    "  plotting_function(range(TRAINING_DATA_LENGTH,TRAINING_DATA_LENGTH+VAL_DATA_LENGTH),val_data[:,0],label=\"validation\")\n",
    "  plotting_function(range(TRAINING_DATA_LENGTH+VAL_DATA_LENGTH,\n",
    "                 TRAINING_DATA_LENGTH+VAL_DATA_LENGTH+TEST_DATA_LENGTH),test_data[:,0],label=\"test\")\n",
    "  plt.ylim([-1000,1000])\n",
    "  plt.figure(figsize=(500,10))\n",
    "  plotting_function(range(TRAINING_DATA_LENGTH),training_data[:,0],label=\"training\")\n",
    "  plt.xlim([0, 100000])\n",
    "  plt.ylim([-100,100])\n",
    "  #plt.legend()\n",
    "print(len(raw_wave)-TRAINING_DATA_LENGTH)\n",
    "print(len(raw_wave2)-VAL_DATA_LENGTH-TEST_DATA_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists(SAVE_PATH):\n",
    "  with open(SAVE_DIR+\"model_params.pckl\", 'rb') as file:\n",
    "    import pickle\n",
    "    mp_loaded = pickle.load(file)\n",
    "  if MP != mp_loaded:\n",
    "    print(MP)\n",
    "    print(mp_loaded)\n",
    "  assert MP == mp_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create Graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "preset_batch_size = None\n",
    "# Placeholders\n",
    "with tf.name_scope(\"input_placeholders\") as scope:\n",
    "  input_placeholders = [tf.placeholder(tf.float32, shape=(preset_batch_size, MP.INPUT_SIZE), name=\"input\"+str(i))\n",
    "                        for i in range(MP.OUTSET_CUTOFF)]\n",
    "dropout_placeholder = tf.placeholder(tf.float32, name=\"dropout_prob\")\n",
    "c_state_placeholders = [tf.placeholder(tf.float32, shape=(preset_batch_size, MP.NUM_UNITS), name=\"c_state\"+str(i)) for i in range(MP.N_LAYERS)]\n",
    "h_state_placeholders = [tf.placeholder(tf.float32, shape=(preset_batch_size, MP.NUM_UNITS), name=\"h_state\"+str(i)) for i in range(MP.N_LAYERS)]\n",
    "initial_state = tuple(tf.nn.rnn_cell.LSTMStateTuple(c_state, h_state) for c_state, h_state in zip(c_state_placeholders, h_state_placeholders))\n",
    "with tf.name_scope(\"target_placeholders\") as scope:\n",
    "  target_placeholders = [tf.placeholder(tf.float32, shape=(preset_batch_size, MP.OUTPUT_SIZE), name=\"target\"+str(i))\n",
    "                        for i in range(MP.BPTT_LENGTH-MP.OUTSET_CUTOFF)]\n",
    "\n",
    "# Cells\n",
    "stacked_lstm_cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "    [tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(MP.NUM_UNITS, state_is_tuple=True),\n",
    "                                   output_keep_prob=dropout_placeholder) for i in range(MP.N_LAYERS)],\n",
    "                                                state_is_tuple=True)\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "state = initial_state\n",
    "unrolled_outputs = []\n",
    "with tf.variable_scope(\"RNN\") as scope:\n",
    "    for time, input_ in enumerate(input_placeholders):\n",
    "       if time > 0:\n",
    "          scope.reuse_variables()\n",
    "       (output, state) = stacked_lstm_cell(input_, state)\n",
    "       unrolled_outputs.append(output)\n",
    "    for i in range(MP.BPTT_LENGTH-MP.OUTSET_CUTOFF):\n",
    "       scope.reuse_variables()\n",
    "       (output, state) = stacked_lstm_cell(output[:, 0:MP.OUTPUT_SIZE], state)\n",
    "       unrolled_outputs.append(output)\n",
    "        \n",
    "outputs = [tf.mul(cell_output[:, 0:MP.OUTPUT_SIZE], tf.constant(MP.SCALE_OUTPUT)) for cell_output in unrolled_outputs]\n",
    "\n",
    "# Loss\n",
    "with tf.variable_scope(\"CostFunction\") as scope:\n",
    "  loss = [tf.square(target_placeholder - output, name=\"loss\"+str(i)) \n",
    "          for i, (target_placeholder, output) in enumerate(zip(target_placeholders, outputs[MP.OUTSET_CUTOFF:]))]\n",
    "  loss = tf.add_n(loss, name=\"summed_seq_loss\") # add together losses for each sequence step\n",
    "  electrode_loss_weights = tf.constant([1.0]+[0.01 for _ in range(MP.OUTPUT_SIZE-1)], name=\"loss_weights\")\n",
    "  loss = tf.mul(loss, electrode_loss_weights, name=\"weighted_loss\") # weigh loss for each electrode\n",
    "  if MP.OUTPUT_SIZE > 1:\n",
    "      loss = tf.reduce_sum(loss, 1) # add together loss for all outputs\n",
    "  cost = tf.reduce_mean(loss, name=\"cost\")   # average over batch\n",
    "\n",
    "# ADAM optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=MP.LEARNING_RATE).minimize(cost)\n",
    "if MP.CLIP_GRADIENTS > 0:\n",
    "  adam = tf.train.AdamOptimizer(learning_rate=MP.LEARNING_RATE)\n",
    "  gvs = adam.compute_gradients(cost)\n",
    "#  capped_gvs = [(tf.clip_by_value(grad, -MP.CLIP_GRADIENTS, MP.CLIP_GRADIENTS), var) for grad, var in gvs]\n",
    "  capped_gvs = [(tf.clip_by_norm(grad, MP.CLIP_GRADIENTS), var) for grad, var in gvs]\n",
    "  optimizer = adam.apply_gradients(capped_gvs)\n",
    "\n",
    "# Initialize session and write graph for visualization.\n",
    "sess = tf.Session()\n",
    "tf.initialize_all_variables().run(session=sess)\n",
    "\n",
    "print(\"Session created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if TENSORBOARD_DIR != None:\n",
    "  summary_writer = tf.train.SummaryWriter(TENSORBOARD_DIR, sess.graph)\n",
    "  print(\"Tensorboard graph saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "import pickle\n",
    "mp_filename = \"model_params.pckl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Restore model weights from previously saved model\n",
    "import os\n",
    "if os.path.exists(SAVE_PATH):\n",
    "  saver.restore(sess, SAVE_PATH)\n",
    "  print(\"Model restored from file: %s\" % SAVE_PATH)\n",
    "else:\n",
    "  print(\"No model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from batchmaker import StatefulBatchmaker\n",
    "\n",
    "total_step_cost = None\n",
    "step_cost_log = []\n",
    "total_val_cost = 0\n",
    "val_cost_log = []\n",
    "val_steps_since_last_improvement = 0\n",
    "make_new_training_batches_and_states = True\n",
    "\n",
    "# single step\n",
    "for step in range(MAX_STEPS):\n",
    "  # Validation\n",
    "  val_batchmaker = StatefulBatchmaker(val_data, MP.BPTT_LENGTH, MP.OUTSET_CUTOFF, BATCH_SIZE, MP.OUTPUT_SIZE)\n",
    "  prev_batch_c_states = [np.zeros((BATCH_SIZE, MP.NUM_UNITS)) for i in range(MP.N_LAYERS)]\n",
    "  prev_batch_h_states = [np.zeros((BATCH_SIZE, MP.NUM_UNITS)) for i in range(MP.N_LAYERS)]\n",
    "  if np.mod(step, VAL_EVERY_N_STEPS) == 0:\n",
    "    total_val_cost = 0\n",
    "    while True:\n",
    "      if BATCH_LIMIT_PER_STEP > 0:\n",
    "        if val_batchmaker.n_batches_consumed() > BATCH_LIMIT_PER_STEP:\n",
    "          break\n",
    "      if val_batchmaker.is_depleted():\n",
    "        break\n",
    "      else:\n",
    "        batch_input_values, batch_target_values = val_batchmaker.next_batch()\n",
    "    \n",
    "        # Assign a value to each placeholder.\n",
    "        feed_dictionary = {ph: v for ph, v in zip(input_placeholders, batch_input_values)}\n",
    "        feed_dictionary[dropout_placeholder] = 1.0\n",
    "        for target_placeholder, target_value in zip(target_placeholders, batch_target_values):\n",
    "            feed_dictionary[target_placeholder] = target_value\n",
    "        for c_state_placeholder, prev_batch_c_state in zip(c_state_placeholders, prev_batch_c_states):\n",
    "            feed_dictionary[c_state_placeholder] = prev_batch_c_state\n",
    "        for h_state_placeholder, prev_batch_h_state in zip(h_state_placeholders, prev_batch_h_states):\n",
    "            feed_dictionary[h_state_placeholder] = prev_batch_h_state\n",
    "\n",
    "       # Validate.\n",
    "        cost_value, state_value = sess.run((cost, state), feed_dict=feed_dictionary)\n",
    "        total_val_cost += cost_value\n",
    "        prev_batch_c_states = [state_value[i].c for i in range(len(state_value))]\n",
    "        prev_batch_h_states = [state_value[i].h for i in range(len(state_value))]\n",
    "    print(\"Validation cost: \", end='')\n",
    "    print(total_val_cost, end='')\n",
    "    print(\"  (Training cost: \", end='')\n",
    "    print(total_step_cost, end='')\n",
    "    print(\")\")\n",
    "    val_cost_log.append(total_val_cost)\n",
    "    \n",
    "    # Training Monitor\n",
    "    if len(val_cost_log) > 1:\n",
    "        # Save cost log.\n",
    "        import os\n",
    "        if not os.path.exists(SAVE_DIR):\n",
    "            os.makedirs(SAVE_DIR)\n",
    "            print(\"Created directory: %s\" % SAVE_DIR)\n",
    "        np.savetxt(SAVE_DIR+\"val_cost_log.txt\", val_cost_log)\n",
    "        # Save if cost has improved. Otherwise increment counter.\n",
    "        if val_cost_log[-1] <  min(val_cost_log[:-1]):\n",
    "            val_steps_since_last_improvement = 0\n",
    "            # save model to disk\n",
    "            print(\"Saving ... \", end='')\n",
    "            save_path = saver.save(sess, SAVE_PATH)\n",
    "            with open(SAVE_DIR+mp_filename, 'wb') as file:\n",
    "              pickle.dump(MP, file, protocol=2)\n",
    "            print(\"Model saved in file: %s\" % save_path)      \n",
    "        else:\n",
    "            val_steps_since_last_improvement += 1         \n",
    "    # Stop training if val_cost hasn't improved in VAL_STEP_TOLERANCE steps\n",
    "    if val_steps_since_last_improvement > VAL_STEP_TOLERANCE:\n",
    "        print(\"Training stopped by validation monitor.\")\n",
    "        break\n",
    "            \n",
    "  # Train on batches\n",
    "  total_step_cost = 0\n",
    "  step_batches_counter = 0\n",
    "  if make_new_training_batches_and_states:\n",
    "    training_batchmaker = StatefulBatchmaker(training_data, MP.BPTT_LENGTH, MP.OUTSET_CUTOFF, BATCH_SIZE, MP.OUTPUT_SIZE)\n",
    "    prev_batch_c_states = [np.zeros((BATCH_SIZE, MP.NUM_UNITS)) for i in range(MP.N_LAYERS)]\n",
    "    prev_batch_h_states = [np.zeros((BATCH_SIZE, MP.NUM_UNITS)) for i in range(MP.N_LAYERS)]\n",
    "    make_new_training_batches_and_states = False\n",
    "  while True:\n",
    "    if BATCH_LIMIT_PER_STEP > 0:\n",
    "      step_batches_counter += 1\n",
    "      if step_batches_counter > BATCH_LIMIT_PER_STEP:\n",
    "        break\n",
    "    if training_batchmaker.is_depleted():\n",
    "      make_new_training_batches_and_states = True\n",
    "      break\n",
    "    else:\n",
    "      batch_input_values, batch_target_values = training_batchmaker.next_batch()\n",
    "      \n",
    "      # Assign a value to each placeholder.\n",
    "      feed_dictionary = {ph: v for ph, v in zip(input_placeholders, batch_input_values)}\n",
    "      feed_dictionary[dropout_placeholder] = MP.DROPOUT\n",
    "      for target_placeholder, target_value in zip(target_placeholders, batch_target_values):\n",
    "        feed_dictionary[target_placeholder] = target_value\n",
    "      for c_state_placeholder, prev_batch_c_state in zip(c_state_placeholders, prev_batch_c_states):\n",
    "        feed_dictionary[c_state_placeholder] = prev_batch_c_state\n",
    "      for h_state_placeholder, prev_batch_h_state in zip(h_state_placeholders, prev_batch_h_states):\n",
    "        feed_dictionary[h_state_placeholder] = prev_batch_h_state\n",
    "  \n",
    "      # Train over 1 batch.\n",
    "      opt_value, last_output_value, cost_value, state_value = sess.run((optimizer, outputs[-1], cost, state),\n",
    "                                                              feed_dict=feed_dictionary)\n",
    "      total_step_cost += cost_value\n",
    "      prev_batch_c_states = [state_value[i].c for i in range(len(state_value))]\n",
    "      prev_batch_h_states = [state_value[i].h for i in range(len(state_value))]\n",
    "      assert not np.isnan(last_output_value).any()\n",
    "  step_cost_log.append(total_step_cost)\n",
    "\n",
    "\n",
    "print(\"Training ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if PLOTTING_SUPPORT:\n",
    "  plt.figure(figsize=(100,10))\n",
    "  plotting_function(range(len(step_cost_log)), step_cost_log, label=\"step_cost_log\")\n",
    "  plotting_function(range(len(val_cost_log)), val_cost_log, label=\"val_cost_log\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Restore model weights from previously saved model\n",
    "import os\n",
    "if os.path.exists(SAVE_PATH):\n",
    "  saver.restore(sess, SAVE_PATH)\n",
    "  print(\"Model restored from file: %s\" % SAVE_PATH)\n",
    "else:\n",
    "  print(\"No model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "REALIGN_OUTPUT = True\n",
    "\n",
    "from batchmaker import StatefulBatchmaker\n",
    "test_batchmaker = StatefulBatchmaker(test_data, MP.BPTT_LENGTH, MP.OUTSET_CUTOFF, 1, MP.OUTPUT_SIZE, True)\n",
    "\n",
    "\n",
    "testing_cost = 0\n",
    "test_outputs = []\n",
    "prev_batch_c_states = [np.zeros((1, MP.NUM_UNITS)) for i in range(len(state_value))]\n",
    "prev_batch_h_states = [np.zeros((1, MP.NUM_UNITS)) for i in range(len(state_value))]\n",
    "while True:\n",
    "  if test_batchmaker.is_depleted():\n",
    "    break\n",
    "  else:\n",
    "    batch_input_values, batch_target_values = test_batchmaker.next_batch()\n",
    "    \n",
    "    # Assign a value to each placeholder.\n",
    "    feed_dictionary = {ph: v for ph, v in zip(input_placeholders, batch_input_values)}\n",
    "    feed_dictionary[dropout_placeholder] = 1.0\n",
    "    for target_placeholder, target_value in zip(target_placeholders, batch_target_values):\n",
    "      feed_dictionary[target_placeholder] = target_value\n",
    "    for c_state_placeholder, prev_batch_c_state in zip(c_state_placeholders, prev_batch_c_states):\n",
    "      feed_dictionary[c_state_placeholder] = prev_batch_c_state\n",
    "    for h_state_placeholder, prev_batch_h_state in zip(h_state_placeholders, prev_batch_h_states):\n",
    "      feed_dictionary[h_state_placeholder] = prev_batch_h_state\n",
    "\n",
    "    # Test over 1 batch.\n",
    "    outputs_value, cost_value, state_value = sess.run((outputs, cost, state), feed_dict=feed_dictionary)\n",
    "    outputs_value = np.array(outputs_value)\n",
    "    testing_cost += cost_value\n",
    "    test_outputs.append(outputs_value[:,0,:])\n",
    "    prev_batch_c_states = [state_value[i].c for i in range(len(state_value))]\n",
    "    prev_batch_h_states = [state_value[i].h for i in range(len(state_value))]\n",
    "    assert not np.isnan(outputs_value[-1]).any()   \n",
    "test_outputs = np.array(test_outputs)\n",
    "\n",
    "if PLOTTING_SUPPORT:\n",
    "  plt.figure(figsize=(TEST_DATA_LENGTH/20,10))\n",
    "  plt.gca().set_prop_cycle(cycler('color', ['k'] + \n",
    "                                           [(1,1,w) for w in np.linspace(0.8,0.5,MP.OUTSET_CUTOFF)] + \n",
    "                                           [(1,w,w) for w in np.linspace(0.4,0,MP.BPTT_LENGTH-MP.OUTSET_CUTOFF)]))\n",
    "  plot_data = np.array(test_data)\n",
    "  if MP.INPUT_SIZE > 1:\n",
    "    plot_data = plot_data[:,0]\n",
    "  plotting_function(range(len(plot_data)), plot_data, label=\"test data\")\n",
    "  if REALIGN_OUTPUT:\n",
    "    abscisses = np.tile(np.arange(MP.OUTSET_CUTOFF, MP.OUTSET_CUTOFF+len(test_outputs))[:,None], (1,MP.BPTT_LENGTH))\n",
    "    abscisses = abscisses + np.arange(MP.BPTT_LENGTH)\n",
    "  else:\n",
    "    abscisses = np.arange(MP.OUTSET_CUTOFF, MP.OUTSET_CUTOFF+len(test_outputs))\n",
    "  plotting_function(abscisses, test_outputs[:,:,0], label=\"prediction\")\n",
    "  plt.legend()\n",
    "  if MP.INPUT_SIZE > 1:\n",
    "    plt.figure(figsize=(TEST_DATA_LENGTH/20,10))\n",
    "    plt.gca().set_prop_cycle(cycler('color', ['k'] + \n",
    "                                             [(1,1,w) for w in np.linspace(0.8,0.5,MP.OUTSET_CUTOFF)] + \n",
    "                                             [(1,w,w) for w in np.linspace(0.4,0,MP.BPTT_LENGTH-MP.OUTSET_CUTOFF)]))\n",
    "    plot_data = np.array(test_data)[:,1]\n",
    "    plotting_function(range(len(plot_data)), plot_data, label=\"electrode 1\")\n",
    "    plotting_function(abscisses, test_outputs[:,:,1], label=\"prediction\")\n",
    "    plt.legend() \n",
    "    plt.figure(figsize=(TEST_DATA_LENGTH/20,10))\n",
    "    plot_data = np.array(test_data)[:,1:]\n",
    "    plotting_function(range(len(plot_data)), plot_data, label=\"electrodes\")\n",
    "    plt.legend()\n",
    "  print(\"Offset: \", end='')\n",
    "  print(offset)\n",
    "print(\"Testing cost: \", end='')\n",
    "print(testing_cost)\n",
    "\n",
    "#Reset test data to normal data\n",
    "offset += TEST_DATA_LENGTH\n",
    "if len(raw_wave2) == 0:\n",
    "  test_data = raw_wave[offset:][TRAINING_DATA_LENGTH:][VAL_DATA_LENGTH:][:TEST_DATA_LENGTH]\n",
    "else:\n",
    "  if len(raw_wave3) == 0:\n",
    "    test_data = raw_wave2[offset:][VAL_DATA_LENGTH:][:TEST_DATA_LENGTH]\n",
    "  else:\n",
    "    test_data = raw_wave3[offset:][:TEST_DATA_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  if PLOTTING_SUPPORT:\n",
    "    from IPython import display\n",
    "    for i in range(len(output_value)):\n",
    "      plotting_function(range(10), test_data[i:i+10][:,0], label='target')\n",
    "      plotting_function(range(10), output_value[i], label='prediction')\n",
    "      plt.legend()\n",
    "      plt.ylim([-100,100])\n",
    "      plt.show()\n",
    "      plt.pause(0.01)\n",
    "      display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Replace test data with sine wave\n",
    "if False:\n",
    "  test_data = np.tile(30*np.sin(np.linspace(0,100*np.pi,TEST_DATA_LENGTH)), (MP.INPUT_SIZE, 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reset test data to normal data\n",
    "offset += TEST_DATA_LENGTH\n",
    "if len(raw_wave2) is 0:\n",
    "  test_data = raw_wave[offset:][TRAINING_DATA_LENGTH:][VAL_DATA_LENGTH:][:TEST_DATA_LENGTH]\n",
    "else:\n",
    "  if len(raw_wave3) is 0:\n",
    "    test_data = raw_wave2[offset:][VAL_DATA_LENGTH:][:TEST_DATA_LENGTH]\n",
    "  else:\n",
    "    test_data = raw_wave3[offset:][:TEST_DATA_LENGTH]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PRE_HALLUCINATION_LENGTH = 1000\n",
    "HALLUCINATION_LENGTH = 500\n",
    "HALLUCINATION_FUTURE = 0\n",
    "\n",
    "from batchmaker import StatefulBatchmaker\n",
    "hal_batchmaker = StatefulBatchmaker(test_data, MP.BPTT_LENGTH, MP.OUTSET_CUTOFF, 1, MP.OUTPUT_SIZE, True)\n",
    "prev_batch_c_states = [np.zeros((1, MP.NUM_UNITS)) for i in range(len(state_value))]\n",
    "prev_batch_h_states = [np.zeros((1, MP.NUM_UNITS)) for i in range(len(state_value))]\n",
    "batch_input_values, batch_target_values = hal_batchmaker.next_batch()\n",
    "\n",
    "hal_target = []\n",
    "pre_hal_output = []\n",
    "hal_output = []\n",
    "for i in range(PRE_HALLUCINATION_LENGTH):\n",
    "  # Assign a value to each placeholder.\n",
    "  feed_dictionary = {ph: v for ph, v in zip(input_placeholders, batch_input_values)}\n",
    "  feed_dictionary[dropout_placeholder] = 1.0\n",
    "  for target_placeholder, target_value in zip(target_placeholders, batch_target_values):\n",
    "    feed_dictionary[target_placeholder] = target_value\n",
    "  for c_state_placeholder, prev_batch_c_state in zip(c_state_placeholders, prev_batch_c_states):\n",
    "    feed_dictionary[c_state_placeholder] = prev_batch_c_state\n",
    "  for h_state_placeholder, prev_batch_h_state in zip(h_state_placeholders, prev_batch_h_states):\n",
    "    feed_dictionary[h_state_placeholder] = prev_batch_h_state\n",
    "\n",
    "  # Run session\n",
    "  outputs_value, state_value = sess.run((outputs, state), feed_dict=feed_dictionary)\n",
    "\n",
    "  prev_batch_c_states = [state_value[i].c for i in range(len(state_value))]\n",
    "  prev_batch_h_states = [state_value[i].h for i in range(len(state_value))]\n",
    "\n",
    "  batch_input_values, batch_target_values = hal_batchmaker.next_batch()\n",
    "  hal_target.append(batch_input_values[-1])\n",
    "  pre_hal_output.append(outputs_value[MP.OUTSET_CUTOFF-1])\n",
    "\n",
    "for i in range(HALLUCINATION_LENGTH):\n",
    "  # Assign a value to each placeholder.\n",
    "  feed_dictionary = {ph: v for ph, v in zip(input_placeholders, batch_input_values)}\n",
    "  feed_dictionary[dropout_placeholder] = 1.0\n",
    "  for target_placeholder, target_value in zip(target_placeholders, batch_target_values):\n",
    "    feed_dictionary[target_placeholder] = target_value\n",
    "  for c_state_placeholder, prev_batch_c_state in zip(c_state_placeholders, prev_batch_c_states):\n",
    "    feed_dictionary[c_state_placeholder] = prev_batch_c_state\n",
    "  for h_state_placeholder, prev_batch_h_state in zip(h_state_placeholders, prev_batch_h_states):\n",
    "    feed_dictionary[h_state_placeholder] = prev_batch_h_state\n",
    "\n",
    "  # Run session\n",
    "  outputs_value, state_value = sess.run((outputs, state), feed_dict=feed_dictionary)\n",
    "  hal_output.append(outputs_value[MP.OUTSET_CUTOFF-1+HALLUCINATION_FUTURE][0,0])\n",
    "\n",
    "  prev_batch_c_states = [state_value[i].c for i in range(len(state_value))]\n",
    "  prev_batch_h_states = [state_value[i].h for i in range(len(state_value))]\n",
    "\n",
    "  #batch_input_values, batch_target_values = hal_batchmaker.next_batch()\n",
    "  #batch_input_values[-1] = outputs_value[MP.OUTSET_CUTOFF-1]\n",
    "\n",
    "  batch_input_values.pop(0)\n",
    "  batch_input_values.append(outputs_value[MP.OUTSET_CUTOFF-1])\n",
    "\n",
    "  actual_input_values, _ = hal_batchmaker.next_batch()\n",
    "  hal_target.append(actual_input_values[-1])\n",
    "\n",
    "if PLOTTING_SUPPORT:\n",
    "  plt.figure(figsize=(100,10))\n",
    "  plt.gca().set_prop_cycle(cycler('color', ['k'] + ['blue'] + ['red']))\n",
    "  plotting_function(range(len(hal_target)), np.array(hal_target)[:,0,0], label=\"test data\")\n",
    "  plotting_function(range(len(pre_hal_output)), np.array(pre_hal_output)[:,0,0], label=\"pre-hallucination\")\n",
    "  plotting_function(range(len(pre_hal_output),len(pre_hal_output)+len(hal_output)),hal_output, label=\"prediction\")\n",
    "  plt.xlim([0,PRE_HALLUCINATION_LENGTH+len(hal_output)])\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You've got mail!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(DATA_FOLDER+\"secret.txt\") as file:\n",
    "    secret=file.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not SET_EULER_PARAMETERS:\n",
    "  import smtplib\n",
    "   \n",
    "  server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "  server.starttls()\n",
    "  server.login(\"brainwavesdev@gmail.com\", secret)\n",
    " \n",
    "  msg = \"Waves brained!\"\n",
    "  server.sendmail(\"brainwavesdev@gmail.com\", \"brainwavesdev@gmail.com\", msg)\n",
    "  server.quit()\n",
    "\n",
    "  print(\"Mail sent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Author: Daniel Dugas"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ml3]",
   "language": "python",
   "name": "Python [ml3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
